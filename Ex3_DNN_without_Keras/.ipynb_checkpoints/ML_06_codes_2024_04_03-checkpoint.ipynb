{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0wY-sjAyIfA"
   },
   "source": [
    "# **Codes to lecture 6.**\n",
    "\n",
    "\n",
    "This notebook includes codes on forward propagation and back propagation calculations for neural network with 2 layers.\n",
    "\n",
    "The first layer consists of 2 neurons and the second layer has also 2 neurons.\n",
    "We use sigmoid as activation function.\n",
    "\n",
    "It is based on example given in prof. B. Dyda notes:\n",
    "https://prac.im.pwr.edu.pl/~bdyda/sem2022zimowy/ml/back-propagation4.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "gJSzYFHi2OZp"
   },
   "source": [
    ">[Codes to lecture 6.](#scrollTo=G0wY-sjAyIfA)\n",
    "\n",
    ">[6.1. Forward propagation and back propagation example for simple neural network.](#scrollTo=Xorai9gk6smc)\n",
    "\n",
    ">[6.1.1 Forward propagation.](#scrollTo=PUzVG0d892Yz)\n",
    "\n",
    ">[6.1.2 Back propagation](#scrollTo=3JRWouppCpQt)\n",
    "\n",
    ">[6.1.3 Weights update.](#scrollTo=Q5HN5T6vPwZq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtczXqpQKhSE"
   },
   "source": [
    "We import Numpy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5U0TlBMWKlHd"
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xorai9gk6smc"
   },
   "source": [
    "# 6.1. Forward propagation and back propagation example for simple neural network.\n",
    "\n",
    "Let us suppose for input\n",
    "$$x = \\begin{bmatrix}\n",
    "1\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "we expect output\n",
    "$$y = \\begin{bmatrix}\n",
    "0\\\\\n",
    "1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "We start with the following weights\n",
    "\n",
    "$W^{(1)} = \\begin{bmatrix}\n",
    "-0.1 & -0.2 & 0.1\\\\\n",
    "-0.4 & 0.7 & -0.6\n",
    "\\end{bmatrix}$\n",
    "\n",
    "and\n",
    "\n",
    "$W^{(2)} = \\begin{bmatrix}\n",
    "-0.15 & -0.25 & 0.15\\\\\n",
    "-0.45 & 0.75 & -0.65\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9V01YG6RycG",
    "outputId": "97d07019-e6b5-4ca8-8ac2-c9afb7534f4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,0]).reshape(2,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9xk_1yoR7g5",
    "outputId": "8d22ad48-d96a-4499-8b0d-658328fcebcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0,1]).reshape(2,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKCfrJza8GWh",
    "outputId": "42a66df4-012d-46e4-a93c-df4a45f5e13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1, -0.2,  0.1],\n",
       "       [-0.4,  0.7, -0.6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = np.array([[-0.1, -0.2, 0.1],\n",
    "               [-0.4, 0.7, -0.6]])\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7bfNxi_8GUP",
    "outputId": "02c0ca3b-621d-46d9-fd70-e8a364b0ee53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15, -0.25,  0.15],\n",
       "       [-0.45,  0.75, -0.65]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = np.array([[-0.15, -0.25, 0.15],\n",
    "               [-0.45, 0.75, -0.65]])\n",
    "W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlT6CDmc9Ohz"
   },
   "source": [
    "Since the first coordinate encodes bias (and thus is always equal to $1$) we denote the input by $X^{[1]}$ as follows\n",
    "\n",
    "$$\n",
    "X^{(1)} = \\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSqTpgBGSB2n",
    "outputId": "46fcd7f6-6343-4e08-cd8b-3d77ff8d0e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.vstack((1,x))\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUzVG0d892Yz"
   },
   "source": [
    "# 6.1.1 Forward propagation.\n",
    "\n",
    "The first layer gives\n",
    "\n",
    "$$\n",
    "net^{[1]} = W^{[1]} \\cdot X^{[1]}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.3\\\\\n",
    "0.3\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV6AuXNG8GSH",
    "outputId": "6aa5ff70-7f88-43db-bb5e-eec1551d8f78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3],\n",
       "       [ 0.3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = np.dot(W1, X1)\n",
    "net1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yf5lS1LV-in1"
   },
   "source": [
    "Applying element-wise the activation function (here: sigmoid $\\varphi$)\n",
    "$$\\varphi(x)=\\frac{e^x}{1+e^x}$$\n",
    "on\n",
    "$$net1 = \\begin{bmatrix}\n",
    "-0.3\\\\\n",
    "0.3\n",
    "\\end{bmatrix}$$\n",
    "we obtain the output $a^{[1]}$ of the first layer:\n",
    "\n",
    "$$a^{[1]}\n",
    "= \\varphi(net1)\n",
    "= \\begin{bmatrix}\n",
    "\\varphi(-0.3)\\\\\n",
    "\\varphi(0.3)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "0.42555748\\\\\n",
    "0.57444252\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQHwIWFg8GPn",
    "outputId": "a5596744-4854-43f9-e759-c31a56feb692"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42555748],\n",
       "       [0.57444252]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "  return np.exp(x) / (1+np.exp(x))\n",
    "\n",
    "a1 = sigmoid(net1)\n",
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVWFFj9TAvQV"
   },
   "source": [
    "We add $1$ as the first coordinate and obtain the input $X^{[2]}$ of the second layer\n",
    "\n",
    "$$X^{[2]} =\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "0.42555748\\\\\n",
    "0.57444252\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g52foVn8GNS",
    "outputId": "330afd82-081a-4b59-cc14-7d8c1e4ed619"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.42555748],\n",
       "       [0.57444252]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.vstack((1,a1))\n",
    "X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bzSWWfwBju_"
   },
   "source": [
    "The second layer (with weights $W^{[2]}$) gives us\n",
    "$$\n",
    "net^{[2]}\n",
    "= W^{[2]} \\cdot X^{[2]}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.17022299\\\\\n",
    "-0.50421952\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgPQaMne8GKy",
    "outputId": "7d411f99-06e2-43ed-ae6e-ffc4ed354bd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17022299],\n",
       "       [-0.50421952]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = np.dot(W2,X2)\n",
    "net2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSsna59ECAAH"
   },
   "source": [
    "One again, we apply the activation function (here: sigmoid $\\varphi$) to $net^{[2]}$ to get the output $a^{[2]}$ of the whole neural network\n",
    "\n",
    "$$a^{[2]}\n",
    "= \\varphi(net^{[2]})\n",
    "= \\begin{bmatrix}\n",
    "\\varphi(-0.17022299) \\\\\n",
    "\\varphi(-0.50421952)\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.45754671\\\\\n",
    "0.37654958\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SeWwZOj0DB1x",
    "outputId": "7fc70891-82ca-4854-b830-6790fc36cab3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45754671],\n",
       "       [0.37654958]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = sigmoid(net2)\n",
    "a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JRWouppCpQt"
   },
   "source": [
    "# 6.1.2 Back propagation\n",
    "\n",
    "Our target value is\n",
    "$$\n",
    "y =\n",
    "\\begin{bmatrix}\n",
    "0\\\\\n",
    "1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Using the loss function\n",
    "\n",
    "$$L(y, a^{[2]}) = \\frac12 ||y-a^{[2]}||_2^2$$\n",
    "\n",
    "we can write\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a^{[2]}} = a^{[2]} - y\n",
    "\\begin{bmatrix}\n",
    "0.45754671\\\\\n",
    "0.37654958\n",
    "\\end{bmatrix}\n",
    "-\n",
    "\\begin{bmatrix}\n",
    "0\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.45754671\\\\\n",
    "-0.62345042\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qhp3vLxHFFIl",
    "outputId": "feee5008-11cf-4b56-d3e0-598deba682ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45754671],\n",
       "       [-0.62345042]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLda2 = a2 - y\n",
    "dLda2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcwFS5DzFVPy"
   },
   "source": [
    "We calculate the delta signal $\\delta^{[2]}$ as follows\n",
    "$$\\delta^{[2]} =\n",
    "\\begin{bmatrix}\n",
    "0.45754671 \\cdot \\varphi'(-0.17022299)\\\\\n",
    "-0.62345042 \\cdot \\varphi'(-0.50421952)\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.11356205\\\\\n",
    "-0.14636122\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Notice that we mulitplied $\\frac{\\partial L}{\\partial a^{[2]}}$ by derivative of $\\varphi$ at the points coresponding to $net2$.\n",
    "\n",
    "Moreover, since $\\varphi$ is a sigmoid function, we can use the following equality (check!)\n",
    "$$\\varphi'(x)=\\varphi(x) \\cdot (1-\\varphi(x)).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vakITcVBEIYQ",
    "outputId": "39188b29-cb0b-4308-b235-762eddf8e8a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11356205],\n",
       "       [-0.14636122]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_derivative(x):\n",
    "  return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "delta2 = dLda2 * sigmoid_derivative(net2)\n",
    "delta2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA_VzZmeG5kf"
   },
   "source": [
    "Thus, the derivative\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W^{[2]}}$$\n",
    "\n",
    "of the loss function $L$ with respect to the weghts $W^{[2]}$ from the second layer $W^{[2]}$ is equal to\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W^{[2]}}\n",
    "= \\delta^{[2]} \\cdot (X^{[2]})^T\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.11356205 &  0.04832718 &  0.06523487\\\\\n",
    "-0.14636122 & -0.06228511 & -0.08407611\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7cKmYP1G5Jr",
    "outputId": "28b8db2a-71f1-49d4-ac79-32ff3f4d5547"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11356205,  0.04832718,  0.06523487],\n",
       "       [-0.14636122, -0.06228511, -0.08407611]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLdW2 = delta2 * X2.T\n",
    "dLdW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtVa5eK_IGHi"
   },
   "source": [
    "We have to move back to the first layer. Thus, we need to find the derivative\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial X^{[2]}} $$\n",
    "\n",
    "of the loss function $L$ with respect to $X^{[2]}$.\n",
    "\n",
    "We can write\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial X^{[2]}}  \n",
    "= (W^{[2]})^T \\cdot \\delta^{[2]}\n",
    "=\\begin{bmatrix}\n",
    "0.04882824\\\\\n",
    "-0.13816143\\\\\n",
    "0.1121691\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9BxIL__G5G3",
    "outputId": "80b25d03-652d-43ff-e46c-5574b85144f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04882824],\n",
       "       [-0.13816143],\n",
       "       [ 0.1121691 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLdX2 = np.dot(W2.T, delta2)\n",
    "dLdX2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvjBpsE6C7LU"
   },
   "source": [
    "We omit the first coordinate (because it is not important i.e. it corresponds to the the constant input $1$ and in fact, it encodes only the bias) and obtain the derivative\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a^{[1]}}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.13816143\\\\\n",
    "0.1121691\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "of the loss function $L$ with respect to the output $a^{[1]} $of the first layer (since $X^{[2]}$ is just $a^{[1]}$ with $1$ added at the first coordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XO-TkwVo8GIi",
    "outputId": "5a671661-c551-4612-f076-e9a13fae2403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13816143],\n",
       "       [ 0.1121691 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLda1 = dLdX2[1:]\n",
    "dLda1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iamuHvIKZLS"
   },
   "source": [
    "Now we are in position to continue in the same way as previously i.e we get the delta signal $\\delta^{[1]}$ as follows\n",
    "\n",
    "$$\\delta^{[1]}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.07511425 \\cdot \\varphi'(-0.1)\\\\\n",
    "-0.09478965 \\cdot \\varphi'(0.1)\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.03377471\\\\\n",
    "0.02742067\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orUzpYY3Jv_4",
    "outputId": "e6b9d6cc-bdb1-4ab6-8478-cd340b2ce4f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03377471],\n",
       "       [ 0.02742067]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta1 = dLda1 * sigmoid_derivative(net1)\n",
    "delta1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rGr-MI-PLNa"
   },
   "source": [
    "Thus, the derivative\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W^{[1]}}$$\n",
    "\n",
    "of the loss function $L$ with respect to the weghts $W^{[1]}$ from the first layer $W^{[1]}$ is equal to\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W^{[1]}}\n",
    "= \\delta^{[1]} \\cdot (X^{[1]})^T\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.03377471 & -0.03377471 & 0\\\\\n",
    "0.02742067 &  0.02742067 &  0\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SO2iA5j7Ph3-",
    "outputId": "5c61cc97-7c4c-4287-dd88-29f3b12f5303"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03377471, -0.03377471, -0.        ],\n",
       "       [ 0.02742067,  0.02742067,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLdW1 = delta1 * X1.T\n",
    "dLdW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5HN5T6vPwZq"
   },
   "source": [
    "# 6.1.3 Weights update.\n",
    "\n",
    "Finally, we can adjust the weights as follows (we set e.g. learning rate $c=0.1$)\n",
    "\n",
    "$$W^{[2]}_{new} = W^{[2]} - c \\frac{\\partial L}{\\partial W^{[2]}}\n",
    "=\\begin{bmatrix}\n",
    "-0.16135621 & -0.25483272 &  0.14347651\\\\\n",
    "-0.43536388 &  0.75622851 & -0.64159239\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLvBfzwIQHMO",
    "outputId": "47475a06-bf42-42c9-855d-6e465a7bfdaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16135621, -0.25483272,  0.14347651],\n",
       "       [-0.43536388,  0.75622851, -0.64159239]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0.1\n",
    "\n",
    "W2new = W2 - c * dLdW2\n",
    "W2new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzBH4sYqQkIn"
   },
   "source": [
    "Similarly, we adjust the weights in the first layer\n",
    "\n",
    "$$W^{[1]}_{new} = W^{[1]} - c \\frac{\\partial L}{\\partial W^{[1]}}\n",
    "=\\begin{bmatrix}\n",
    "-0.09662253 & -0.19662253 &  0.1\\\\\n",
    "-0.40274207 &  0.69725793 & -0.6\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhdTOzSSQiyF",
    "outputId": "4c7d758e-8e1f-48da-8b87-8e572cd8228e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09662253, -0.19662253,  0.1       ],\n",
       "       [-0.40274207,  0.69725793, -0.6       ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1new = W1 - c * dLdW1\n",
    "W1new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNqU7on5REdo"
   },
   "source": [
    "That is all -  we obtained the neural network with new weights!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
